todo   speed->               DQN->SAC    reward = -30?

log env with reward shape 1


todo : change to see the vehicle behind  and the order from last

DQN7 SB1 vehicle lines 5, 10, 4  reward[25-30]  yrange 10->15  step X10
    result cant see the vehicle behind
DQN6 SB1 vehicle lines 5, 10, 4  reward[25-30]  yrange 10->15
DQN5 SB1 vehicle lines 5, 10, 4  reward[20-30]
DQN4 SB3 vehicle lines 5, 10, 4  reward[ 0-30]
DQN3 SB1 vehicle lines 5, 10, 4  reward[ 0-30]
DQN2 SB3 vehicle lines 3, 5,  2  reward[ 0-30]
DQN1 SB1 vehicle lines 3, 5,  2  reward[ 0-30]
    result good at den 0.5  but 1 and line 3


config = {
    "observation": {
        "type": "Kinematics",
        "vehicles_count": 3,  # !!!!!!!!!!!!
        # "features": ["presence", "x", "y", "vx", "vy", "cos_h", "sin_h"],
        "features": ["x", "y", "vx","vy"],

        "features_range": {
            "x": [-100, 100],
            "y": [-10, 10],
            "vx": [-30, 30],
            "vy": [-30, 30],
        },
        "absolute": False,
        "order": "sorted"
    },
    "action": {
        "type": "DiscreteMetaAction",
    },
    "lanes_count": 2,
    "initial_lane_id": None,
    "vehicles_count": 5,                # ! !!!!!!!!!!!
    "controlled_vehicles": 1,
    "duration": 50,  # [step]             # !!!!!!!!!!!!!!
    "ego_spacing": 2,
    "initial_spacing": 2,
    "collision_reward": -1000,  # The reward received when colliding with a vehicle.
    "reward_speed_range": [0, 30],  # [m/s] The reward for high speed is mapped linearly from this range to [0, HighwayEnv.HIGH_SPEED_REWARD].
    "right_lane_reward": 0,  # The reward received when driving on the right-most lanes, linearly mapped to
    # zero for other lanes.
    "high_speed_reward": 1,  # The reward received when driving at full speed, linearly mapped to zero for
    # lower speeds according to config["reward_speed_range"].
    "simulation_frequency": 10,  # [Hz]
    "policy_frequency": 1,  # [Hz]
    "other_vehicles_type": "highway_env.vehicle.behavior.IDMVehicle",
    "screen_width": 600,  # [px]
    "screen_height": 150,  # [px]
    "centering_position": [0.3, 0.5],
    "scaling": 5.5,
    "show_trajectories": False,
    "render_agent": True,
    "offscreen_rendering": False,
    "vehicles_density": 1,
    "offroad_terminal": False
}


env = gym.make('highway-v0')
env.configure(config)
env.reset()



# model= DQN(MlpPolicy,env,verbose=1,
#            tensorboard_log="../../Data/tensorboard_log_fello/",
#            exploration_fraction= 0.1,
#            exploration_initial_eps = 1.0,
#            exploration_final_eps= 0.05,
#            learning_rate=0.01,
#            learning_starts=100,
#            gamma=0.9)